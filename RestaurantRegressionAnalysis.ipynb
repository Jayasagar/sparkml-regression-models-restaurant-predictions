{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "\n",
    "#Plotting \n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Main model imports\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Restaurant_train_Remove_Header.csv\"\n",
    "raw_data = sc.textFile(path)\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x: x.split(\",\"))\n",
    "first = records.first()\n",
    "print('First record: ', first)\n",
    "print('Total number of records: ', num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cache\n",
    "records.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map categorical features into a binary vector form\n",
    "def get_mapping(rdd, idx):\n",
    "    print('index:', idx)\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()\n",
    "\n",
    "print(\"Categorical feature Type Mapping Output: %s\" % get_mapping(records, 1))\n",
    "\n",
    "#Apply Mapping function for two categorical columns\n",
    "mappings = [get_mapping(records, i) for i in range(0,2)]\n",
    "\n",
    "cat_len = sum([len(b) for b in mappings])\n",
    "num_len = len(records.first()[2:39])\n",
    "total_len = num_len + cat_len\n",
    "\n",
    "#We now have the mappings for each variable, and we can see how many values in total we need for our binary vector representation:\n",
    "\n",
    "print(\"Feature vector length for categorical features: %d\" % cat_len)\n",
    "print(\"Feature vector length for numerical features: %d\" % num_len)\n",
    "print(\"Total feature vector length: %d\" % total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the extracted mappings get binary-encoded features from the categorical features.\n",
    "#Note: Re-used this logic from Bike share assignment.\n",
    "def extract_features(record):\n",
    "    cat_vec = np.zeros(cat_len)\n",
    "    i = 0\n",
    "    step = 0\n",
    "    for field in record[0:1]: # catogorical feature\n",
    "        print('extract_features', i)\n",
    "        m = mappings[i]\n",
    "        idx = m[field]\n",
    "        cat_vec[idx + step] = 1\n",
    "        i = i + 1\n",
    "        step = step + len(m)\n",
    "    num_vec = np.array([float(field) for field in record[2:38]])\n",
    "    return np.concatenate((cat_vec, num_vec))\n",
    "\n",
    "#extract_label function changes to float\n",
    "def extract_label(record):\n",
    "    return float(record[-1])\n",
    "# Root Suarred Error\n",
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2\n",
    "\n",
    "# Aboslute Error\n",
    "def abs_error(actual, pred):\n",
    "     return np.abs(pred - actual)\n",
    "# Mean Squared Error     \n",
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Task: DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Label and Feature Vector from the Dataset \n",
    "# 2.1.1 Decision Tree Categorical features\n",
    "\n",
    "decision_tree_data = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))\n",
    "\n",
    "first_point_decision_tree = decision_tree_data.first()\n",
    "print(\"Raw data: \" + str(first[2:]))\n",
    "print(\"Decision Tree regression output label: \" + str(first_point_decision_tree.label))\n",
    "print(\"Decision Tree regression feature vector: \" + str(first_point_decision_tree.features))\n",
    "print(\"Decision Tree regression feature vector length: \" + str(len(first_point_decision_tree.features)))\n",
    "\n",
    "(trainData_decision_tree, testData_decision_tree) = decision_tree_data.randomSplit([0.7, 0.3])\n",
    "model_decision_tree = DecisionTree.trainRegressor(trainData_decision_tree, categoricalFeaturesInfo={},\n",
    "                                    impurity='variance', maxDepth=10, maxBins=64)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions_decision_tree = model_decision_tree.predict(testData_decision_tree.map(lambda x: x.features))\n",
    "labelsAndPredictions_decision_tree = testData_decision_tree.map(lambda lp: lp.label).zip(predictions_decision_tree)\n",
    "\n",
    "print('Learned regression tree model:')\n",
    "print(model_decision_tree.toDebugString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2) Decision Tree Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_decision_tree = np.sqrt(labelsAndPredictions_decision_tree.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse = labelsAndPredictions_decision_tree.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae = labelsAndPredictions_decision_tree.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "\n",
    "print(\"Decision Tree Model - Root Mean Squared Log Error: %2.4f\" % rmsle_decision_tree)\n",
    "print(\"Decision Tree Model - Mean Squared Error: %2.4f\" % mse)\n",
    "print(\"Decision Tree Model - Mean Absolute Error: %2.4f\" % mae)\n",
    "\n",
    "targets = records.map(lambda r: float(r[-1])).collect()\n",
    "hist(targets, bins=20, color='lightblue', normed=True)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_tree(trainData, testData, maxDepthValue, maxBinsValue):\n",
    "    modelDT = DecisionTree.trainRegressor(trainData, categoricalFeaturesInfo={},\n",
    "                                    impurity='variance', maxDepth=maxDepthValue, maxBins=maxBinsValue)\n",
    "\n",
    "    # Evaluate model on test instances and compute test error\n",
    "    predits = modelDT.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredicts = testData.map(lambda lp: lp.label).zip(predits)\n",
    "    rmsleDT = np.sqrt(labelsAndPredicts.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsleDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3) Decision Tree Max Bins\n",
    "constantMaxDepthAndBinsParams = [5, 10, 20, 30, 40, 50]\n",
    "\n",
    "metrics = [evaluate_decision_tree(trainData_decision_tree, testData_decision_tree, 20, param) # constant Max Depth\n",
    "           for param in constantMaxDepthAndBinsParams]\n",
    "print(constantMaxDepthAndBinsParams)\n",
    "print(metrics)\n",
    "\n",
    "# Plotting\n",
    "plot(constantMaxDepthAndBinsParams, metrics)\n",
    "plt.xlabel('Max bins')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.4) Decision Tree Max Depth\n",
    "\n",
    "maxDepthAndConstantBinsParams = [5, 10, 12, 15, 20, 25]\n",
    "\n",
    "metricsMaxDepth = [evaluate_decision_tree(trainData_decision_tree, testData_decision_tree, param, 150) \n",
    "           for param in maxDepthAndConstantBinsParams]\n",
    "print(maxDepthAndConstantBinsParams)\n",
    "print(metricsMaxDepth)\n",
    "\n",
    "# Plotting\n",
    "plot(maxDepthAndConstantBinsParams, metricsMaxDepth)\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Gradient boost tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a GradientBoostedTrees model.\n",
    "model_gradient_tree = GradientBoostedTrees.trainRegressor(trainData_decision_tree,\n",
    "                                            categoricalFeaturesInfo={}, numIterations=5, maxDepth=15, maxBins=32)\n",
    "predictions_gradient_tree = model_gradient_tree.predict(testData_decision_tree.map(lambda x: x.features))\n",
    "labelsAndPredictions_gradient_tree = testData_decision_tree.map(lambda lp: lp.label).zip(predictions_gradient_tree)\n",
    "\n",
    "print('Completed Gradient boosted tree model building:')\n",
    "print(model_gradient_tree.toDebugString())\n",
    "\n",
    "rmsle_gradient_tree = np.sqrt(labelsAndPredictions_gradient_tree.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse_gradient_tree = labelsAndPredictions_gradient_tree.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae_gradient_tree = labelsAndPredictions_gradient_tree.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "\n",
    "print(\"Gradient boosted tree Model - Root Mean Squared Log Error: %2.4f\" % rmsle_gradient_tree)\n",
    "print(\"Gradient boosted tree Model - Mean Squared Error: %2.4f\" % mse_gradient_tree)\n",
    "print(\"Gradient boosted tree Model - Mean Absolute Error: %2.4f\" % mae_gradient_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1) Gradient boost tree iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gradient_tree(trainData, testData, numIterationsValue, maxDepthValue, maxBinsValue):\n",
    "    model_gradient_tree = GradientBoostedTrees.trainRegressor(trainData,\n",
    "                                            categoricalFeaturesInfo={}, numIterations=numIterationsValue,\n",
    "                                                    maxDepth=maxDepthValue, maxBins=maxBinsValue)\n",
    "\n",
    "    predictions_gradient_tree = model_gradient_tree.predict(testData.map(lambda x: x.features))\n",
    "    labelsAndPredictions_gradient_tree = testData.map(lambda lp: lp.label).zip(predictions_gradient_tree)\n",
    "    rmsle_gradient_tree = np.sqrt(labelsAndPredictions_gradient_tree.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsle_gradient_tree\n",
    "\n",
    "numInterationsParams = [2, 3, 4, 5, 6]\n",
    "\n",
    "metrics_gradient_tree_iterations = [evaluate_gradient_tree(trainData_decision_tree, testData_decision_tree, param, 10, 32)\n",
    "           for param in numInterationsParams]\n",
    "print(numInterationsParams)\n",
    "print(metrics_gradient_tree_iterations)\n",
    "\n",
    "# Plotting\n",
    "plot(numInterationsParams, metrics_gradient_tree_iterations)\n",
    "plt.xlabel('Iterations log scale')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2) Gradient boost tree Max Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxBinsParams = [5, 10, 15, 20 , 25]\n",
    "\n",
    "metrics_gradient_tree_maxBins = [evaluate_gradient_tree(trainData_decision_tree, testData_decision_tree, 3, 5, param)\n",
    "           for param in maxBinsParams]\n",
    "print(maxBinsParams)\n",
    "print(metrics_gradient_tree_maxBins)\n",
    "\n",
    "# Plotting : Decision Tree Max Depth\n",
    "plot(maxBinsParams, metrics_gradient_tree_maxBins)\n",
    "plt.xlabel('Max Bins')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2.3 - Gradient boost tree Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepthParams = [5, 10, 15, 20, 25]\n",
    "\n",
    "metrics_gradient_tree_maxDepth = [evaluate_gradient_tree(trainData_decision_tree, testData_decision_tree, 3, param, 32)\n",
    "           for param in maxDepthParams]\n",
    "print(maxDepthParams)\n",
    "print(metrics_gradient_tree_maxDepth)\n",
    "\n",
    "# Plotting\n",
    "plot(maxDepthParams, metrics_gradient_tree_maxDepth)\n",
    "plt.xlabel('Max Depths')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Task - Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can proceed with extracting feature vectors and labels from our data records\n",
    "data_linear_regression = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))\n",
    "\n",
    "# Let's inspect the first record in the extracted feature RDD:\n",
    "\n",
    "first_point = data_linear_regression.first()\n",
    "print(\"Raw data: \" + str(first[2:]))\n",
    "print(\"Label: \" + str(first_point.label))\n",
    "print(\"Linear Model feature vector:\\n\" + str(first_point.features))\n",
    "print(\"Linear Model feature vector length: \" + str(len(first_point.\n",
    "features)))\n",
    "\n",
    "(trainData_linear_regression, testData_linear_regression) = data_linear_regression.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_regression = LinearRegressionWithSGD.train(trainData_linear_regression, iterations=20, step=0.01)\n",
    "# Building a Regression Model with Spark\n",
    "true_vs_predicted_linear_regression = testData_linear_regression.map(lambda p: (p.label, model_linear_regression.predict(p.features)))\n",
    "print(\"Linear Model predictions: \" + str(true_vs_predicted_linear_regression.take(5)))\n",
    "\n",
    "\n",
    "predictions_linear_regression = model_linear_regression.predict(testData_linear_regression.map(lambda x: x.features))\n",
    "labelsAndPredictions_linear_regression = testData_linear_regression.map(lambda lp: lp.label).zip(predictions_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.1 - Linear regression Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data size', trainData_linear_regression.count())\n",
    "print('Test data size', testData_linear_regression.count())\n",
    "\n",
    "print('Total data size', trainData_linear_regression.count() + testData_linear_regression.count())\n",
    "\n",
    "\n",
    "def evaluate(train, test, iterations, step, regParam, regType, intercept):\n",
    "    model = LinearRegressionWithSGD.train(train, iterations, step, \n",
    "                                          regParam=regParam, regType=regType, intercept=intercept)\n",
    "    tp = test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    rmsle = np.sqrt(tp.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "    return rmsle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2.1 - Intercept\n",
    "\n",
    "params_intercept = [True, False]\n",
    "metrics_intercept = [evaluate(trainData_linear_regression, testData_linear_regression, 3, 0.01, 0.0, 'l2', param) for param in params_intercept]\n",
    "\n",
    "print(params_intercept)\n",
    "print(metrics_intercept)\n",
    "\n",
    "# Plotting\n",
    "plot(params_intercept, metrics_intercept)\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2.2 - Iterations\n",
    "\n",
    "params_iterations = [3, 6, 9, 12]\n",
    "metrics_iterations = [evaluate(trainData_linear_regression, testData_linear_regression, param, 0.01, 0.0, 'l2', False) for param in params_iterations]\n",
    "\n",
    "print(params_iterations)\n",
    "print(metrics_iterations)\n",
    "\n",
    "# Plotting\n",
    "plot(params_iterations, metrics_iterations)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2.3 -  Step size\n",
    "\n",
    "params_step = [0.01, 0.05, 0.075, 0.5, 1]\n",
    "metrics_step = [evaluate(trainData_linear_regression, testData_linear_regression, 3, param, 0.0, 'l2', False) for param in params_step]\n",
    "\n",
    "print(params_step)\n",
    "print(metrics_step)\n",
    "\n",
    "# Plotting\n",
    "plot(params_step, metrics_step)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2.4 - L1 Regularization\n",
    "\n",
    "params_l1 = params = [0.0, 0.1, 0.5, 1.0, 10.0, 100.0]\n",
    "metrics_l1 = [evaluate(trainData_linear_regression, testData_linear_regression, 3, 0.01, param, 'l1', False) for param in params_l1]\n",
    "\n",
    "print(params_l1)\n",
    "print(metrics_l1)\n",
    "\n",
    "# Plotting\n",
    "plot(params_l1, metrics_l1)\n",
    "plt.xlabel('L1 Regularization')\n",
    "plt.ylabel('RMSLE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2.4 - L2 Regularization\n",
    "\n",
    "params_l2 = params = [0.0, 0.01, 0.05, 0.5, 1.0, 5.0]\n",
    "metrics_l2 = [evaluate(trainData_linear_regression, testData_linear_regression, 5, 0.01, param, 'l2', False) for param in params_l2]\n",
    "\n",
    "print(params_l2)\n",
    "print(metrics_l2)\n",
    "\n",
    "# Plotting\n",
    "plot(params_l2, metrics_l2)\n",
    "plt.xlabel('L2 Regularization')\n",
    "plt.ylabel('RMSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.3 - Linear regression Log\n",
    "\n",
    "rmsle_lr = np.sqrt(labelsAndPredictions_linear_regression.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse_lr = labelsAndPredictions_linear_regression.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae_lr = labelsAndPredictions_linear_regression.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "\n",
    "print(\"Linear regression Log - Root Mean Squared Log Error: %2.4f\" % rmsle_lr)\n",
    "print(\"Linear regression Log - Mean Squared Error: %2.4f\" % mse_lr)\n",
    "print(\"Linear regression Log - Mean Absolute Error: %2.4f\" % mae_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
